{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch\n",
    "# %pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import captum\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerConductance\n",
    "from captum.attr import NeuronConductance\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update path to dataset here.\n",
    "dataset_path = \"titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset from csv file.\n",
    "titanic_data = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   \n",
       "0            1         0       3  \\\n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp   \n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos cargados, ahora preprocesamos los datos convirtiendo algunas características categóricas como el género, la ubicación del embarque y la clase de pasajero en codificaciones únicas (columnas de características separadas para cada clase con 0/1). \n",
    "También eliminamos algunas características que son más difíciles de analizar, como el nombre, y completamos los valores faltantes en la edad y la tarifa con los valores promedio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, cada categoría en cada columna se convertirá en un número entero único. Sin embargo, ten en cuenta que si hay una relación ordinal entre las categorías, como en el caso de \"Pclass\" (clase de pasajero), podría ser más apropiado utilizar el enfoque de variables ficticias (dummy variables) para evitar la interpretación errónea de un orden implícito.\n",
    "\n",
    "Al final, la elección entre LabelEncoder y el enfoque de variables ficticias depende del contexto y la naturaleza de tus datos. Si no hay un orden implícito entre las categorías y el modelo de aprendizaje automático que utilizarás puede manejar variables categóricas codificadas de manera ordinal, LabelEncoder puede ser una opción adecuada. Sin embargo, si las categorías no tienen un orden natural o el orden puede introducir sesgos, es preferible utilizar el enfoque de variables ficticias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.concat([titanic_data,\n",
    "                          pd.get_dummies(titanic_data['Sex'], dtype=int),\n",
    "                          pd.get_dummies(titanic_data['Embarked'],prefix=\"Embark\", dtype=int),\n",
    "                          pd.get_dummies(titanic_data['Pclass'],prefix=\"Class\", dtype=int)], axis=1)\n",
    "\n",
    "titanic_data[\"Age\"] = titanic_data[\"Age\"].fillna(titanic_data[\"Age\"].mean())\n",
    "titanic_data[\"Fare\"] = titanic_data[\"Fare\"].fillna(titanic_data[\"Fare\"].mean())\n",
    "\n",
    "titanic_data = titanic_data.drop(['PassengerId', 'Name','Ticket','Sex','Embarked','Pclass', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>Embark_C</th>\n",
       "      <th>Embark_Q</th>\n",
       "      <th>Embark_S</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  female  male  Embark_C  Embark_Q   \n",
       "0         0  22.0      1      0   7.2500       0     1         0         0  \\\n",
       "1         1  38.0      1      0  71.2833       1     0         1         0   \n",
       "2         1  26.0      0      0   7.9250       1     0         0         0   \n",
       "3         1  35.0      1      0  53.1000       1     0         0         0   \n",
       "4         0  35.0      0      0   8.0500       0     1         0         0   \n",
       "\n",
       "   Embark_S  Class_1  Class_2  Class_3  \n",
       "0         1        0        0        1  \n",
       "1         0        1        0        0  \n",
       "2         1        0        0        1  \n",
       "3         1        1        0        0  \n",
       "4         1        0        0        1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el DataFrame en un archivo CSV\n",
    "titanic_data.to_csv('titanic_data.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después del procesamiento, las características que tenemos son:\n",
    "\n",
    "Age  - Edad del Pasajero  \n",
    "Sibsp - Número de hermanos/cónyuges a bordo  \n",
    "Parch - Número de padres/hijos a bordo  \n",
    "Fare  - Importe de tarifa pagado en libras esterlinas  \n",
    "Female  - Variable binaria que indica si el pasajero es mujer  \n",
    "Male  - Variable binaria que indica si el pasajero es hombre  \n",
    "EmbarkC - Variable binaria que indica si el pasajero se embarcó en Cherburgo  \n",
    "EmbarkQ: variable binaria que indica si el pasajero se embarcó en Queenstown  \n",
    "EmbarkS - Variable binaria que indica si el pasajero se embarcó en Southampton  \n",
    "Class1 - Variable binaria que indica si el pasajero estaba en primera clase  \n",
    "Class2 - Variable binaria que indica si el pasajero estaba en segunda clase  \n",
    "Class3 - Variable binaria que indica si el pasajero estaba en tercera clase  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convertimos los datos en matrices numpy y separamos los conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility.\n",
    "np.random.seed(131254)\n",
    "\n",
    "# Convert features and labels to numpy arrays.\n",
    "labels = titanic_data[\"Survived\"].to_numpy()\n",
    "titanic_data = titanic_data.drop(['Survived'], axis=1)\n",
    "feature_names = list(titanic_data.columns)\n",
    "data = titanic_data.to_numpy()\n",
    "\n",
    "# Separate training and test sets using \n",
    "train_indices = np.random.choice(len(labels), int(0.7*len(labels)), replace=False)\n",
    "test_indices = list(set(range(len(labels))) - set(train_indices))\n",
    "train_features = data[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "test_features = data[test_indices]\n",
    "test_labels = labels[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 12)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora estamos listos para definir la arquitectura de la red neuronal que usaremos para la tarea.  Hemos definido una arquitectura simple utilizando 2 capas ocultas, la primera con 12 unidades ocultas y la segunda con 8 unidades ocultas, cada una con no linealidad sigmoide.  La capa final realiza una operación softmax y tiene 2 unidades, correspondientes a las salidas de sobrevivido (1) o no sobrevivido (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # Set seed for reproducibility.\n",
    "\n",
    "class TitanicSimpleNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(12, 12)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(12, 8)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.linear3 = nn.Linear(8, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lin1_out = self.linear1(x)\n",
    "        sigmoid_out1 = self.sigmoid1(lin1_out)\n",
    "        sigmoid_out2 = self.sigmoid2(self.linear2(sigmoid_out1))\n",
    "        return self.softmax(self.linear3(sigmoid_out2))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float()\n",
    "        elif isinstance(x, torch.Tensor):\n",
    "            x = x.float()\n",
    "            \n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.forward(x)\n",
    "        predicted_probs = torch.softmax(output, dim=1)\n",
    "        return predicted_probs\n",
    "\n",
    "\n",
    "    \n",
    "    def predict_lime(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float()\n",
    "        elif isinstance(x, torch.Tensor):\n",
    "            x = x.float()\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.forward(x)\n",
    "        predicted_probs = torch.softmax(output, dim=1)\n",
    "        _, predicted_labels = torch.max(predicted_probs, 1)\n",
    "        return predicted_probs.detach().numpy()\n",
    "    \n",
    "# Declaramos una nueva instancia de clase\n",
    "net = TitanicSimpleNNModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar un modelo previamente entrenado o entrenar la red usando los datos de entrenamiento para 200 épocas. Tenga en cuenta que los resultados de los pasos posteriores pueden no coincidir si se vuelve a entrenar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 => Loss: 0.73\n",
      "Epoch 21/200 => Loss: 0.53\n",
      "Epoch 41/200 => Loss: 0.49\n",
      "Epoch 61/200 => Loss: 0.49\n",
      "Epoch 81/200 => Loss: 0.48\n",
      "Epoch 101/200 => Loss: 0.47\n",
      "Epoch 121/200 => Loss: 0.47\n",
      "Epoch 141/200 => Loss: 0.47\n",
      "Epoch 161/200 => Loss: 0.47\n",
      "Epoch 181/200 => Loss: 0.47\n"
     ]
    }
   ],
   "source": [
    "net = TitanicSimpleNNModel()\n",
    "USE_PRETRAINED_MODEL = False\n",
    "\n",
    "if USE_PRETRAINED_MODEL:\n",
    "    net.load_state_dict(torch.load('titanic_model.pt'))\n",
    "    print(\"Model Loaded!\")\n",
    "\n",
    "    input_tensor = torch.from_numpy(train_features).type(torch.BoolTensor)  # Para convertir datos booleanos\n",
    "    input_tensor = torch.from_numpy(train_features).type(torch.FloatTensor) # Para convertir datos enteros\n",
    "\n",
    "    input_tensor = torch.from_numpy(train_features.astype(float)).type(torch.FloatTensor) # Para convertir datos enteros y booleanos\n",
    "    label_tensor = torch.from_numpy(train_labels)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    num_epochs = 200\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "    # input_tensor = torch.from_numpy(train_features).type(torch.FloatTensor)\n",
    "\n",
    "    input_tensor = torch.from_numpy(train_features.astype(float)).type(torch.FloatTensor) # Para convertir datos enteros y booleanos\n",
    "    label_tensor = torch.from_numpy(train_labels)\n",
    "\n",
    "    for epoch in range(num_epochs):    \n",
    "        output = net(input_tensor)\n",
    "        loss = criterion(output, label_tensor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 20 == 0:\n",
    "            print ('Epoch {}/{} => Loss: {:.2f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "    torch.save(net.state_dict(), 'titanic_fcnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8346709470304976\n"
     ]
    }
   ],
   "source": [
    "out_probs = net(input_tensor).detach().numpy()\n",
    "out_classes = np.argmax(out_probs, axis=1)\n",
    "print(\"Train Accuracy:\", sum(out_classes == train_labels) / len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8134328358208955\n"
     ]
    }
   ],
   "source": [
    "# test_input_tensor = torch.from_numpy(test_features).type(torch.FloatTensor)\n",
    "test_input_tensor = torch.from_numpy(test_features.astype(float)).type(torch.FloatTensor) # Para convertir datos enteros y booleanos\n",
    "\n",
    "out_probs = net(test_input_tensor).detach().numpy()\n",
    "out_classes = np.argmax(out_probs, axis=1)\n",
    "print(\"Test Accuracy:\", sum(out_classes == test_labels) / len(test_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probamos el método \"predict_lime\" de la clase \"TitanicSimpleNNModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[0.73105633 0.26894373]] Input size:  torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "single_input = test_input_tensor[0].unsqueeze(0)\n",
    "predict = net.predict_lime(single_input)\n",
    "print( 'Prediction: ',predict, 'Input size: ', single_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[0.73105633 0.26894373]\n",
      " [0.52732056 0.47267947]\n",
      " [0.731056   0.268944  ]\n",
      " [0.26898634 0.7310137 ]\n",
      " [0.7310548  0.26894525]\n",
      " [0.73087317 0.26912677]\n",
      " [0.693822   0.306178  ]\n",
      " [0.2713691  0.7286309 ]\n",
      " [0.2690988  0.7309011 ]\n",
      " [0.7310555  0.26894453]] Input size:  torch.Size([10, 12])\n"
     ]
    }
   ],
   "source": [
    "multiple_input = test_input_tensor[:10]\n",
    "predict = net.predict_lime(multiple_input)\n",
    "print( 'Prediction: ',predict, 'Input size: ', multiple_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  tensor([[0.7311, 0.2689]], grad_fn=<SoftmaxBackward0>) Input size:  torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "single_input = test_input_tensor[0].unsqueeze(0)\n",
    "predict = net.predict(single_input)\n",
    "print( 'Prediction: ',predict, 'Input size: ', single_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  tensor([[0.7311, 0.2689],\n",
      "        [0.5273, 0.4727],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.2690, 0.7310],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.7309, 0.2691],\n",
      "        [0.6938, 0.3062],\n",
      "        [0.2714, 0.7286],\n",
      "        [0.2691, 0.7309],\n",
      "        [0.7311, 0.2689]], grad_fn=<SoftmaxBackward0>) Input size:  torch.Size([10, 12])\n"
     ]
    }
   ],
   "source": [
    "input = test_input_tensor[:10]\n",
    "predict = net.predict(input)\n",
    "print( 'Prediction: ',predict, 'Input size: ', input.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el modelo que vamos a almacenar en un archivo para poder utilizarlo sin tener que recrear todo el proceso en otro archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TitanicSimpleNNModel(\n",
       "  (linear1): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (sigmoid1): Sigmoid()\n",
       "  (linear2): Linear(in_features=12, out_features=8, bias=True)\n",
       "  (sigmoid2): Sigmoid()\n",
       "  (linear3): Linear(in_features=8, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cargamos el modelo para comprobar que se ha guardado con sus características \n",
    "model = TitanicSimpleNNModel()\n",
    "\n",
    "# Cargar los pesos del modelo desde el archivo\n",
    "model.load_state_dict(torch.load('titanic_fcnn.pt'))\n",
    "\n",
    "# Asegurarse de que el modelo esté en modo de evaluación (si corresponde)\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
